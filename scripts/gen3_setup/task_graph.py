import os
import sys
import re
import time
import pickle
import subprocess
import configparser
import numpy as np
import networkx
from lsst.daf.butler import DimensionUniverse
from lsst.pipe.base import QuantumGraph, QuantumGraphTaskNodes

FILENODE = 0
TASKNODE = 1

def pretty_dataset_label(orig_name):
    """Tweak dataset for a label
    Parameters
    ----------
    orig_name : `str`
        dataset as str
    Returns
    -------
    new_name : `str`
        reformatted dataset for label
    """
    new_name = re.sub(r": ", "=", orig_name)
    new_name = re.sub(r"\+", "\n", new_name)
    new_name = re.sub(r",", "\n", new_name)
    new_name = re.sub(r"[\{\}]", "", new_name)
    return new_name

class PipelineGraph:
    def __init__(self, qgraph_file):
        self.sci_graph = None
        self.qgnodes = None
        self.pipeline = None
        with open(qgraph_file, 'rb') as fd:
            self.qgraph = QuantumGraph.load(fd, DimensionUniverse())
        self.create_science_graph()

    def create_science_graph(self):
        """
        This code is copied from
        https://github.com/lsst/ctrl_bps/blob/master/python/lsst/ctrl/bps/bps_core.py
        and modified for this lighter weight class.

        Create expanded graph from the QuantumGraph that has explicit
        dependencies and has individual nodes for each input/output
        dataset.

        Parameters
        ----------
        qgraph : `QuantumGraph`
            QuantumGraph for the pipeline (as generated by the
            QuantumGraph Generator)
        """
        self.sci_graph = networkx.DiGraph()
        ncnt = 0
        tcnt = 0
        dcnt = 0
        dsname_to_node_id = {}
        self.qgnodes = {}
        pipeline = []
        for task_id, nodes in enumerate(self.qgraph):
            task_def = nodes.taskDef
            pipeline.append(task_def.label)
            for quantum in nodes.quanta:
                ncnt += 1
                tcnt += 1
                tnode_name = "task%d (%s)" % (ncnt, task_def.taskName)
                #tnode_name = "%06d" % (ncnt)
                self.sci_graph.add_node(
                    tnode_name,
                    node_type=TASKNODE,
                    task_def_id=task_id,
                    task_abbrev=task_def.label,
                    shape="box",
                    fillcolor="gray",
                    # style='"filled,bold"',
                    style="filled",
                    label=".".join(task_def.taskName.split(".")[-2:]),
                )
                quanta2 = [quantum]
                self.qgnodes[tnode_name] \
                    = QuantumGraphTaskNodes(task_def, quanta2,
                                            quantum.initInputs, {})

                # Make nodes for inputs
                for ds_refs in quantum.predictedInputs.values():
                    for ds_ref in ds_refs:
                        ds_name = f"{ds_ref.datasetType.name}+{ds_ref.dataId}"
                        if ds_name not in dsname_to_node_id:
                            ncnt += 1
                            dcnt += 1
                            dsname_to_node_id[ds_name] = ncnt
                        fnode_name = "%06d" % dsname_to_node_id[ds_name]
                        fnode_desk = pretty_dataset_label(ds_name)
                        self.sci_graph.add_node(
                            fnode_name, node_type=FILENODE,
                            label=fnode_desk, shape="box", style="rounded"
                        )
                        self.sci_graph.add_edge(fnode_name, tnode_name)
                # Make nodes for outputs
                for ds_refs in quantum.outputs.values():
                    for ds_ref in ds_refs:
                        ds_name = f"{ds_ref.datasetType.name}+{ds_ref.dataId}"
                        if ds_name not in dsname_to_node_id:
                            ncnt += 1
                            dcnt += 1
                            dsname_to_node_id[ds_name] = ncnt
                        fnode_name = "%06d" % dsname_to_node_id[ds_name]
                        fnode_desk = pretty_dataset_label(ds_name)
                        self.sci_graph.add_node(
                            fnode_name, node_type=FILENODE,
                            label=fnode_desk, shape="box", style="rounded"
                        )
                        self.sci_graph.add_edge(tnode_name, fnode_name)
        self.pipeline = pipeline


def write_qgnode(qgnode, outfile):
    os.makedirs(os.path.dirname(outfile), exist_ok=True)
    qgraph = QuantumGraph()
    qgraph.append(qgnode)
    with open(outfile, 'wb') as fd:
        pickle.dump(qgraph, fd)


class Task:
    def __init__(self, taskname):
        self.taskname = taskname
        self.dependencies = set()
        self.prereqs = dict()
        self.done = False
        self.task_graph = None

    def add_dependency(self, dependency):
        self.dependencies.add(dependency)

    def add_prereq(self, prereq):
        self.prereqs[prereq] = False

    def run(self, dt=0.1):
        qgnode = self.task_graph.pipeline.qgnodes[self.taskname]
        qgnode_dir = self.task_graph.config['qgnode_dir']
        if not all(self.prereqs.values()) or self.done:
            return
        print('running', self.taskname)
        task_id = self.taskname.split()[0]
        quantum_file = os.path.join(qgnode_dir, f'{task_id}.pickle')
        write_qgnode(qgnode, quantum_file)
        configs = dict(self.task_graph.config)
        configs['quantum_file'] = quantum_file
        command = '''time pipetask run -b %(butlerConfig)s \\
            -i %(inCollection)s \\
            --output-run %(outCollection)s --extend-run --skip-init-writes \\
            --qgraph %(quantum_file)s --skip-existing \\
            --no-versions''' % configs
        print(command)
        sys.stdout.flush()
        subprocess.check_call(command, shell=True)
        print('\n')
        self.finish()

    def finish(self):
        self.done = True
        for dependency in self.dependencies:
            if self not in dependency.prereqs:
                raise RuntimeError('inconsistent dependency')
            dependency.prereqs[self] = True

    def __str__(self):
        return self.taskname

    def __repr__(self):
        return f'Task("{self.taskname}")'


class TaskGraph(dict):
    def __init__(self, config):
        super(TaskGraph, self).__init__()
        self.config = config
        self._tasks = None
        self.ingest_pipeline()

    def __getitem__(self, key):
        if not key in self:
            super(TaskGraph, self).__setitem__(key, Task(key))
            self[key].task_graph = self
        return super(TaskGraph, self).__getitem__(key)

    def __setitem__(self, key, value):
        if key in self:
            raise RuntimeError(f'{key} already in TaskGraph')
        super(TaskGraph, self).__setitem__(key, value)
        self[key].task_graph = self

    def done(self):
        return all(_.done for _ in self.values())

    def tasks(self):
        if self._tasks is None:
            self._tasks = [_ for _ in super(TaskGraph, self).values()]
            np.random.shuffle(self._tasks)
        return self._tasks

    def run_pipeline(self, dt=1):
        command = '''time pipetask run -b %(butlerConfig)s \\
            -i %(inCollection)s \\
            --output-run %(outCollection)s --init-only --skip-existing \\
            --register-dataset-types --qgraph %(qgraph_file)s \\
            --no-versions''' % self.config
        print(command)
        sys.stdout.flush()
        try:
            subprocess.check_call(command, shell=True)
        except subprocess.CalledProcessError as eobj:
            print("Error encountered initializing the pipeline:")
            print(eobj)

        print('\n')
        while not self.done():
            for task in self.tasks():
                task.run(dt=dt)

    def state(self):
        items = []
        for task_name, task in self.items():
            items.append(task_name)
            items.append('   prereqs: ' + str(task.prereqs))
            items.append('   dependencies: ' + str(task.dependencies))
            items.append('')
        return '\n'.join(items)

    def ingest_pipeline(self):
        self.pipeline = PipelineGraph(self.config['qgraph_file'])
        graph = self.pipeline.sci_graph
        for task_name in graph:
            if not task_name.startswith('task'):
                continue
            for output in graph.successors(task_name):
                for successor_task in graph.successors(output):
                    self[task_name].add_dependency(self[successor_task])
                    self[successor_task].add_prereq(self[task_name])


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print(f'usage: python {sys.argv[0]} <config_file>')
        sys.exit(0)

    cp = configparser.ConfigParser()
    cp.optionxform = str
    cp.read(sys.argv[1])
    config = dict(cp.items('DEFAULT'))

    my_tasks = TaskGraph(config)

    print(my_tasks.state())
    print()

    my_tasks.run_pipeline()

    print()
    print(my_tasks.state())
